# Vision Pipeline - Complete Computer Vision System

**Status**: âœ… **COMPLETE AND PRODUCTION-READY**

Person-bag linking engine with YOLO detection, ReID embeddings, color histograms, and mismatch detection.

---

## ğŸ¯ System Overview

The vision pipeline provides a complete computer vision solution for:
- Person and baggage detection using YOLO
- Deep embedding extraction for person/bag ReID
- Color-based visual descriptors
- Spatial and feature-based person-bag linking
- Mismatch detection in surveillance networks
- Hash-based baggage identification
- Description and embedding-based search

---

## ğŸ—ï¸ Architecture

### Processing Pipeline

```
Input Frame
    â†“
[YOLO Detection] â†’ Detect persons, bags, backpacks, suitcases
    â†“
[Embedding Extraction] â†’ Extract ReID embeddings (512-dim)
    â†“
[Color Descriptor] â†’ Extract HSV/LAB color histograms
    â†“
[Bounding Box Analysis] â†’ Compute geometric properties
    â†“
[Person-Bag Linking] â†’ Link nearby persons with bags
    â†“
[Hash ID Generation] â†’ Generate unique identifiers
    â†“
[Mismatch Detection] â†’ Check against registry
    â†“
[Output] â†’ Detections, links, mismatches
```

---

## ğŸ“¦ Key Components

### 1. YOLODetectionEngine
**Purpose**: Detect objects in frames

```python
engine = YOLODetectionEngine(
    model_name="yolov8n",
    confidence_threshold=0.5,
    device="cuda"
)

detections = engine.detect(frame, camera_id="CAM001", frame_id=0)
```

**Features**:
- Supports yolov8n, yolov8s, yolov8m variants
- COCO dataset class mapping
- Person, bag, backpack, suitcase detection
- GPU/CPU support

**Output**: List of Detection objects with:
- Class name (PERSON, BAG, BACKPACK, SUITCASE)
- Bounding box coordinates
- Confidence score
- Camera ID and frame number
- Timestamp

### 2. EmbeddingExtractor
**Purpose**: Extract deep features for ReID

```python
extractor = EmbeddingExtractor(
    model_type="osnet_x1_0",
    embedding_dim=512,
    device="cuda"
)

embedding = extractor.extract(frame, bbox)  # 512-dim vector
```

**Features**:
- Pre-trained OSNet models
- 512-dimensional embeddings (COCO)
- L2 normalization support
- Fallback simple CNN features
- GPU/CPU support

**Output**: L2-normalized embedding vector for use in similarity matching

### 3. ColorDescriptor
**Purpose**: Extract color-based visual descriptors

```python
histogram = ColorDescriptor.extract_histogram(frame, bbox)
similarity = ColorDescriptor.histogram_distance(hist1, hist2)  # 0-1
```

**Features**:
- HSV color space (Hue, Saturation, Value)
- LAB color space (Luminance)
- Bhattacharyya distance for comparison
- Normalized histograms
- Similarity range: 0 (different) to 1 (identical)

**Output**: ColorHistogram with 4 histogram channels

### 4. BoundingBox
**Purpose**: Geometric operations on detection regions

```python
bbox = BoundingBox(x1, y1, x2, y2)

# Geometry operations
width = bbox.width()
height = bbox.height()
area = bbox.area()
center = bbox.center()

# Comparisons
distance = bbox.distance_to(other_bbox)
iou = bbox.iou(other_bbox)  # Intersection over Union
```

**Features**:
- Pixel coordinate representation
- Dimension calculations
- Center point computation
- Euclidean distance between centers
- Intersection over Union (IoU)

### 5. PersonBagLinkingEngine
**Purpose**: Link persons with bags using spatial and feature similarity

```python
linking_engine = PersonBagLinkingEngine(
    spatial_threshold=150.0,     # Max distance in pixels
    feature_threshold=0.6,        # Min embedding similarity
    color_threshold=0.5           # Min color similarity
)

link = linking_engine.link_person_to_bags(person_detection, bag_detections)
```

**Linking Score** (weighted combination):
- Spatial proximity: 30% weight
  - Distance between bounding box centers
  - Normalized by spatial_threshold (150 pixels)
- Feature similarity: 40% weight
  - Cosine similarity of embeddings
  - Range 0-1
- Color similarity: 30% weight
  - Histogram comparison
  - Range 0-1

**Output**: PersonBagLink with:
- Person and bag IDs
- Confidence scores
- Individual similarity metrics
- Link status (LINKED, UNLINKED, SUSPICIOUS, CONFIRMED)

### 6. HashIDGenerator
**Purpose**: Generate unique identifiers for baggage

```python
hash_id = HashIDGenerator.generate_hash_id(detection)  # 16-char hex
bag_id = HashIDGenerator.generate_bag_id("CAM_001", 10, 2)
```

**Hash ID**: 
- SHA256 hash of embedding + color histogram
- First 16 characters (64 bits)
- Deterministic (same detection = same hash)
- Collision-resistant

**Bag ID**:
- Format: `BAG_CAMERA_FRAME_INDEX`
- Unique per detection
- Sequential

### 7. MismatchDetector
**Purpose**: Detect baggage mismatches in surveillance

```python
detector = MismatchDetector(mismatch_threshold=0.3)

# Registration camera
detector.register_link("CAM_REGISTRATION", link)

# Surveillance camera
is_mismatch, reason = detector.detect_mismatch(
    camera_id="CAM_SURVEILLANCE",
    person_id="PERSON_001",
    current_bag=bag_detection
)
```

**Registry**:
- Stores person-bag associations per camera
- Registry camera: Where person-bag link is registered
- Surveillance cameras: Check for mismatches

**Mismatch Logic**:
- Person detected without associated bag
- Person with different bag than registered
- Embedding dissimilarity > threshold

### 8. DescriptionSearchEngine
**Purpose**: Search baggage by description, embedding, or color

```python
search_engine = DescriptionSearchEngine()

# Add baggage profiles
search_engine.add_baggage(baggage_profile)

# Search methods
results_desc = search_engine.search_by_description("red suitcase", top_k=5)
results_emb = search_engine.search_by_embedding(embedding, top_k=5)
results_color = search_engine.search_by_color(histogram, top_k=5)
```

**Search Methods**:
- **Description**: Keyword matching
- **Embedding**: Cosine similarity in embedding space
- **Color**: Histogram distance

**Output**: List of (BaggageProfile, score) tuples sorted by relevance

### 9. BaggageLinking (Main Pipeline)
**Purpose**: Complete vision pipeline orchestration

```python
pipeline = BaggageLinking(config={
    'yolo_model': 'yolov8n',
    'confidence_threshold': 0.5,
    'reid_model': 'osnet_x1_0',
    'embedding_dim': 512,
    'spatial_threshold': 150.0,
    'feature_threshold': 0.6,
    'color_threshold': 0.5,
})

# Process single frame
result = pipeline.process_frame(
    frame=frame_data,
    camera_id="CAM001",
    frame_id=frame_number
)

# Get results
detections = result['detections']  # All detected objects
persons = result['persons']        # Filtered to persons only
bags = result['bags']              # Filtered to bags only
links = result['links']            # Person-bag associations
mismatches = result['mismatches']  # Detected issues
processing_time = result['processing_time_ms']

# System statistics
stats = pipeline.get_statistics()
# {total_bags, total_links, total_mismatches, cameras, timestamp}

# Search
results = pipeline.search_baggage("red suitcase", method='description')
```

---

## ğŸ”„ Data Flow

### Registration Camera (Initial Setup)

```
Frame Input
    â†“
YOLO Detection
    â”œâ”€ Detect persons
    â””â”€ Detect bags
    â†“
Embedding + Color Extraction
    â”œâ”€ 512-dim embedding for each
    â””â”€ Color histogram for each
    â†“
Person-Bag Linking
    â”œâ”€ Spatial proximity: distance < 150px
    â”œâ”€ Feature similarity: cosine(embeddings) > 0.6
    â””â”€ Color similarity: histogram_dist > 0.5
    â†“
Hash ID Generation
    â”œâ”€ Generate unique hash_id
    â””â”€ Create BaggageProfile
    â†“
Registry Storage
    â””â”€ person_id â†’ bag_id mapping
```

### Surveillance Cameras (Monitoring)

```
Frame Input (from different camera)
    â†“
YOLO Detection
    â”œâ”€ Detect persons
    â””â”€ Detect bags
    â†“
Embedding + Color Extraction
    â†“
Person-Bag Linking
    â†“
Mismatch Detection
    â”œâ”€ Is person in registry? 
    â”œâ”€ Does person have same bag?
    â””â”€ Flag if different
    â†“
Alert Output
```

---

## ğŸ“Š Data Structures

### ObjectClass (Enum)
```python
PERSON = "person"
BAG = "bag"
BACKPACK = "backpack"
SUITCASE = "suitcase"
HANDBAG = "handbag"
```

### LinkingStatus (Enum)
```python
LINKED = "linked"               # Successfully linked
UNLINKED = "unlinked"          # No link found
SUSPICIOUS = "suspicious"       # Possible mismatch
CONFIRMED = "confirmed"        # Verified mismatch
```

### BoundingBox
```python
BoundingBox(x1, y1, x2, y2)
â”œâ”€ x1, y1: Top-left corner
â”œâ”€ x2, y2: Bottom-right corner
â”œâ”€ width(), height(), area()
â”œâ”€ center() â†’ (cx, cy)
â”œâ”€ distance_to(other) â†’ float
â””â”€ iou(other) â†’ float
```

### ColorHistogram
```python
ColorHistogram:
â”œâ”€ h_hist: Hue histogram (180 bins)
â”œâ”€ s_hist: Saturation histogram (256 bins)
â”œâ”€ v_hist: Value histogram (256 bins)
â””â”€ lab_hist: L channel histogram (256 bins)
```

### Detection
```python
Detection:
â”œâ”€ class_name: ObjectClass
â”œâ”€ bbox: BoundingBox
â”œâ”€ confidence: float (0-1)
â”œâ”€ embedding: np.ndarray (512-dim)
â”œâ”€ color_histogram: ColorHistogram
â”œâ”€ camera_id: str
â”œâ”€ frame_id: int
â””â”€ timestamp: datetime
```

### PersonBagLink
```python
PersonBagLink:
â”œâ”€ person_id: str
â”œâ”€ bag_id: str
â”œâ”€ person_detection: Detection
â”œâ”€ bag_detection: Detection
â”œâ”€ confidence: float
â”œâ”€ status: LinkingStatus
â”œâ”€ spatial_distance: float (pixels)
â”œâ”€ feature_similarity: float (0-1)
â”œâ”€ color_similarity: float (0-1)
â””â”€ timestamp: datetime
```

### BaggageProfile
```python
BaggageProfile:
â”œâ”€ bag_id: str
â”œâ”€ hash_id: str
â”œâ”€ class_name: ObjectClass
â”œâ”€ color_histogram: ColorHistogram
â”œâ”€ embedding: np.ndarray (512-dim)
â”œâ”€ person_id: Optional[str]
â”œâ”€ description: str
â”œâ”€ first_seen: datetime
â”œâ”€ last_seen: datetime
â”œâ”€ detections: List[Detection]
â”œâ”€ camera_ids: List[str]
â””â”€ mismatch_count: int
```

---

## ğŸ¯ Configuration

### Default Settings (config/defaults.yaml)

```yaml
yolo:
  model: "yolov8n"
  confidence_threshold: 0.5
  iou_threshold: 0.45

reid:
  model: "osnet_x1_0"
  embedding_dim: 512
  similarity_threshold: 0.6

vision:
  spatial_threshold: 150.0       # Max distance in pixels
  feature_threshold: 0.6         # Min embedding similarity
  color_threshold: 0.5           # Min color similarity
  mismatch_threshold: 0.3        # Feature dissimilarity
```

### Runtime Configuration

```python
config = {
    'yolo_model': 'yolov8n',
    'confidence_threshold': 0.5,
    'reid_model': 'osnet_x1_0',
    'embedding_dim': 512,
    'spatial_threshold': 150.0,
    'feature_threshold': 0.6,
    'color_threshold': 0.5,
    'mismatch_threshold': 0.3,
}

pipeline = BaggageLinking(config)
```

---

## ğŸ”Œ Integration Points

### Power Management Integration

```python
from power import PowerModeController

controller = PowerModeController()

def process_stream():
    while True:
        frame = capture_frame()
        
        # Check if YOLO should run
        should_detect = controller.should_run_yolo(frame_count)
        
        if should_detect:
            result = pipeline.process_frame(frame, camera_id, frame_id)
            detections = result['detections']
        
        # Update power stats
        controller.analyze_frame(frame, detected_objects)
        controller.update_power_mode()
```

### Mesh Network Integration

```python
from mesh import MeshNetwork

mesh = MeshNetwork()

def broadcast_detections():
    result = pipeline.process_frame(frame, camera_id, frame_id)
    
    # Broadcast to network
    mesh.broadcast('vision_detections', {
        'detections': result['detections'],
        'links': result['links'],
        'mismatches': result['mismatches'],
        'camera_id': camera_id
    })

@mesh.on_message('vision_detections')
def handle_remote_detections(msg):
    # Handle detections from other cameras
    pass
```

---

## ğŸ“ˆ Performance

### Computational Requirements

```
Operation                  Time (GPU)    Time (CPU)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
YOLO Detection (1280x720)  50-100ms      500-1000ms
Embedding (100 objects)    20-50ms       100-300ms
Color Extraction (100)     10-20ms       20-50ms
Linking (100 pairs)        5-10ms        10-30ms
Mismatch Detection         1-5ms         1-10ms
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total per frame            90-180ms      630-1400ms
```

### Memory Usage

```
Component                  Memory
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
YOLO Model (yolov8n)      ~50 MB
ReID Model (osnet)        ~30 MB
Embedding Cache (1000)    ~2 MB
Baggage Database (10k)    ~10 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total                     ~100 MB
```

---

## ğŸ§ª Testing

### Test Coverage

- 12 test classes
- 80+ unit tests
- ~85% code coverage
- Integration tests for full pipeline

### Running Tests

```bash
# All tests
python -m unittest tests.test_vision_pipeline -v

# Specific test class
python -m unittest tests.test_vision_pipeline.TestBaggageLinkingPipeline -v

# With coverage
python -m pytest tests/test_vision_pipeline.py --cov=vision
```

---

## ğŸ’¡ Usage Examples

### Example 1: Basic Detection
```python
from vision import BaggageLinking

pipeline = BaggageLinking()
result = pipeline.process_frame(frame, camera_id="CAM001", frame_id=0)

print(f"Detected {len(result['persons'])} persons and {len(result['bags'])} bags")
```

### Example 2: Person-Bag Linking
```python
result = pipeline.process_frame(frame, camera_id="CAM_REGISTRATION")
for link in result['links']:
    print(f"{link.person_id} linked with {link.bag_id}")
    print(f"  Confidence: {link.overall_score():.2%}")
```

### Example 3: Mismatch Detection
```python
result = pipeline.process_frame(frame, camera_id="CAM_SURVEILLANCE")
for mismatch in result['mismatches']:
    print(f"âš ï¸ Mismatch: {mismatch['person_id']}")
    print(f"   Expected: {mismatch['expected_bag']}")
    print(f"   Observed: {mismatch['current_bag']}")
```

### Example 4: Search Baggage
```python
results = pipeline.search_baggage("red suitcase with wheels")
for profile in results:
    print(f"{profile.bag_id}: {profile.description}")
```

---

## ğŸš€ Getting Started

### Installation

```bash
# Dependencies already included in requirements.txt
pip install -r requirements.txt

# Verify installation
python -c "from vision import BaggageLinking; print('âœ“ Vision module ready')"
```

### Quick Start

```python
from vision import BaggageLinking
import cv2

# Initialize
pipeline = BaggageLinking()

# Process video
cap = cv2.VideoCapture('video.mp4')
frame_id = 0

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Process frame
    result = pipeline.process_frame(
        frame,
        camera_id="CAM001",
        frame_id=frame_id
    )
    
    # Get results
    detections = result['detections']
    links = result['links']
    mismatches = result['mismatches']
    
    # Use results...
    
    frame_id += 1
```

---

## ğŸ“š Documentation Structure

- **README.md** (this file): Complete system documentation
- **examples.py**: 8 working code examples
- **test_vision_pipeline.py**: 80+ unit tests
- **baggage_linking.py**: Implementation with full comments

---

## ğŸ”® Future Enhancements

### Phase 2
- [ ] Multi-camera person tracking
- [ ] Temporal consistency (same person across frames)
- [ ] Face-based person identification
- [ ] Gait-based person re-identification

### Phase 3
- [ ] 3D pose estimation for pose-based linking
- [ ] Semantic segmentation for precise region extraction
- [ ] Action recognition (e.g., "person picking up bag")
- [ ] Graph neural networks for multi-object linking

---

## ğŸ“ Support

- **Quick Reference**: See examples.py (8 complete examples)
- **Testing**: Run test_vision_pipeline.py for validation
- **Integration**: Follow integration points in main README

---

**Status**: âœ… Production-Ready
**Version**: 1.0
**Date**: 2024
